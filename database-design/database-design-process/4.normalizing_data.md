# Normalizing Data

Another way to make a database more flexible and robust is to 'normalize' it. Normalization makes the database more able to accommodate changes in the structure of the data. It also protects the database against certain kinds of errors.

## What Is Normalization?

Depending on how you design a relational database, it may be susceptible to all sorts of problems:

- It may contain lots of duplicated data. This not only wastes space but it also makes updating all of those duplicated values a time-consuming chore.
- It may incorrectly associate two unrelated pieces of data so you cannot delete one without deleting the other.
- It may require a piece of data that shouldn't exist in order to represent another piece of data that should exist.
- It may limit the number of values that you can enter for what should be a multi-valued piece of data.

Normalization is a process of rearranging the database to put it into a standard (normal) form that prevents these kinds of anomalies.

These are seven different levels of normalization. Each level includes those before it.

The different levels of normalization in order from weakest to strongest are:
❑ First Normal Form (1NF)
❑ Second Normal Form (2NF)
❑ Third Normal Form (3NF)
❑ Boyce-Codd Normal Form (BCNF)
❑ Fourth Normal Form (4NF)
❑ Fifth Normal Form (5NF)
❑ Domain/Key Normal Form (DKNF)

### First Normal Form (1NF)

First Normal Form basically says that data is in a database. Most of the properties needed to be in 1NF are enforced automatically by any reasonable relational database. There are a couple of extra properties added on to make the database more useful, but mostly these rules are pretty basic.

The official qualifications for 1NF are:

- Each column must have a unique name
- the order of the rows and columns doesn't matter
- Each column must have a single data type
- No two rows can contain identical values, thus every table should have a primary key
- Each column must contain a single value. This is the most tempting to violate. Sometimes a data entity includes a concept that needs multiple values. Storing multiple values in a single field limits the usefulness of that field. The solution is to break the multiple values apart, move them into a new table, and link those records back to this one with this record's primary key.
- Columns cannot contain repeating groups

### Second Normal Form (2NF)

A table is in 2NF if:

1. It is in 1NF
2. All of the non-key fields depend on all of the key fields.

Example:

![](/assets/2nf.PNG)
![](/assets/2nf2.PNG)

Though this table is in 1NF, it is trying to do too much work all by itself.

First, the table is vulnerable to update anomalies. An update anomaly occurs when a change to a row leads to inconsistent data. In this case, update anomalies are caused by the fact that this table holds a lot of repeated data.

Second, this table is susceptible to deletion anomalies. A deletion anomaly occurs when deleting a record can destroy information you might need later.In this example, suppose you cancel the 3:30 match featuring Mike Acosta. In that case you lose the entire 7th record in the table, so you lose the fact that Mike is an amateur, that he’s ranked 6th, and even that he exists.

Third, this table is subject to insertion anomalies. An insertion anomaly occurs when you cannot store certain kinds of information because it would violate the table's primary key constraints.Suppose you want to add a new wrestler Nate Waffle to the roster but you have not yet scheduled any matches for him. To add Nate to this table, you would have to assign
him a wrestling match.Similarly, you cannot create a new time for a match without assigning a wrestler to it.
